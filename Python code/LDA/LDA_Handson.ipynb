{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d417466",
   "metadata": {},
   "outputs": [],
   "source": [
    "-> LDA is a linear model for classification and dimensionality reduction\n",
    "-> Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf1d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Why LDA?\n",
    "-> Logistic reg is most popular linear classification models that perform binary classification but \n",
    "falls short in multiclass classification\n",
    "\n",
    "\"Instead of finding new axes that maximize the variation in the data, \n",
    "it focuses on maximinzing the seperability among the know classes in the target columns\"\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LDA()\n",
    "1) Supervised\n",
    "2) How n_components should be selected?\n",
    "\n",
    "==> min(n_classes-1, no.of features) ==> min(10-1,64) ==> 9 < no.of unique categories in target\n",
    "#n_classes --> unique categories in the target variable \n",
    "#no. of fetures --> no.of independent columns\n",
    "\n",
    "min(8,3) ==> 3\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebc27629",
   "metadata": {},
   "source": [
    "Steps to perform LDA:\n",
    "    1) Import the libraries\n",
    "    2) Data loading\n",
    "    4) EDA\n",
    "    3) Standardizing\n",
    "    4) x & y, train test split\n",
    "    5) Model building\n",
    "       LDA\n",
    "       Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a400601",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis #LDA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3e060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b5da0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bde894b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ee5990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2     3     4     5    6    7    8    9   ...   54   55  \\\n",
       "0     0.0  0.0   5.0  13.0   9.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1     0.0  0.0   0.0  12.0  13.0   5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "2     0.0  0.0   0.0   4.0  15.0  12.0  0.0  0.0  0.0  0.0  ...  5.0  0.0   \n",
       "3     0.0  0.0   7.0  15.0  13.0   1.0  0.0  0.0  0.0  8.0  ...  9.0  0.0   \n",
       "4     0.0  0.0   0.0   1.0  11.0   0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...   ...  ...   ...   ...   ...   ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1792  0.0  0.0   4.0  10.0  13.0   6.0  0.0  0.0  0.0  1.0  ...  4.0  0.0   \n",
       "1793  0.0  0.0   6.0  16.0  13.0  11.0  1.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "1794  0.0  0.0   1.0  11.0  15.0   1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1795  0.0  0.0   2.0  10.0   7.0   0.0  0.0  0.0  0.0  0.0  ...  2.0  0.0   \n",
       "1796  0.0  0.0  10.0  14.0   8.0   1.0  0.0  0.0  0.0  2.0  ...  8.0  0.0   \n",
       "\n",
       "       56   57   58    59    60    61   62   63  \n",
       "0     0.0  0.0  6.0  13.0  10.0   0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  11.0  16.0  10.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0   3.0  11.0  16.0  9.0  0.0  \n",
       "3     0.0  0.0  7.0  13.0  13.0   9.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0   2.0  16.0   4.0  0.0  0.0  \n",
       "...   ...  ...  ...   ...   ...   ...  ...  ...  \n",
       "1792  0.0  0.0  2.0  14.0  15.0   9.0  0.0  0.0  \n",
       "1793  0.0  0.0  6.0  16.0  14.0   6.0  0.0  0.0  \n",
       "1794  0.0  0.0  2.0   9.0  13.0   6.0  0.0  0.0  \n",
       "1795  0.0  0.0  5.0  12.0  16.0  12.0  0.0  0.0  \n",
       "1796  0.0  1.0  8.0  12.0  14.0  12.0  1.0  0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d06f1212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0be8c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21efad85fd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[1], cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2338d277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 8, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95bc9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdafb301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cecff028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e437bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "daea1f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0., 10., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  4., 16., ...,  7.,  4.,  0.],\n",
       "       [ 0.,  0.,  5., ...,  2.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  4., ...,  3.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1., 15., ...,  5.,  1.,  0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85cb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    " #0.,  0., 10. - 999\n",
    "# 0.,  3., 15 - 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4ecadc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c512555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f54055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.DataFrame(digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42f930ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "1    182\n",
       "5    182\n",
       "4    181\n",
       "6    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.value_counts() #y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "649dcb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components=9) #min(9,64)\n",
    "X_train = lda.fit_transform(X_train, y_train)\n",
    "X_test = lda.transform(X_test) \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae8b22",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1dbf1dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train,y_train) #training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78c255b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(X_test) #y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ce2b3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 3, 3, 1, 3, 6, 9, 6, 1, 4, 8, 8, 4, 5, 8, 8, 3, 6, 9, 1, 9, 2,\n",
       "       2, 5, 7, 6, 8, 8, 2, 2, 6, 0, 2, 2, 3, 0, 2, 6, 0, 0, 2, 1, 3, 9,\n",
       "       1, 2, 2, 3, 7, 0, 9, 1, 2, 4, 4, 0, 7, 6, 7, 3, 9, 9, 0, 3, 1, 2,\n",
       "       5, 6, 6, 8, 2, 4, 9, 4, 4, 1, 2, 0, 6, 6, 5, 7, 0, 4, 9, 2, 6, 8,\n",
       "       1, 9, 4, 0, 9, 0, 7, 6, 2, 0, 6, 8, 1, 0, 6, 6, 3, 4, 7, 9, 4, 2,\n",
       "       6, 5, 6, 0, 5, 5, 9, 8, 1, 8, 1, 0, 4, 9, 4, 5, 3, 4, 7, 7, 8, 9,\n",
       "       8, 1, 1, 8, 2, 6, 6, 4, 0, 9, 6, 6, 4, 2, 3, 6, 6, 4, 0, 1, 1, 7,\n",
       "       3, 7, 8, 0, 1, 6, 2, 3, 9, 2, 2, 1, 7, 4, 0, 4, 7, 5, 5, 7, 9, 1,\n",
       "       5, 4, 9, 4, 8, 1, 3, 4, 9, 1, 1, 4, 3, 5, 2, 4, 7, 6, 9, 6, 8, 0,\n",
       "       2, 1, 0, 8, 0, 2, 0, 9, 2, 9, 2, 3, 6, 2, 7, 9, 2, 4, 0, 8, 8, 1,\n",
       "       9, 2, 4, 4, 0, 3, 5, 5, 6, 5, 9, 9, 9, 4, 9, 8, 3, 8, 2, 0, 6, 6,\n",
       "       3, 0, 7, 2, 6, 0, 1, 1, 9, 9, 3, 7, 4, 1, 8, 9, 0, 2, 3, 0, 5, 2,\n",
       "       4, 2, 7, 7, 9, 0, 5, 8, 6, 2, 4, 2, 3, 4, 3, 8, 5, 8, 4, 5, 5, 2,\n",
       "       4, 5, 0, 3, 9, 2, 0, 5, 0, 1, 1, 7, 7, 1, 2, 3, 9, 5, 4, 3, 2, 1,\n",
       "       5, 4, 1, 9, 1, 8, 9, 3, 2, 7, 9, 8, 9, 4, 4, 4, 1, 6, 4, 6, 0, 2,\n",
       "       0, 9, 7, 7, 6, 1, 3, 9, 7, 3, 2, 4, 7, 3, 9, 8, 5, 5, 0, 2, 6, 3,\n",
       "       0, 9, 2, 4, 9, 0, 4, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00694eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 3, 3, 1, 3, 6, 9, 6, 1, 4, 8, 8, 4, 5, 8, 8, 3, 6, 9, 1, 9, 2,\n",
       "       2, 5, 7, 6, 8, 8, 2, 2, 6, 0, 2, 2, 3, 0, 2, 6, 0, 0, 2, 1, 3, 9,\n",
       "       1, 2, 2, 5, 7, 0, 9, 2, 2, 4, 4, 0, 7, 6, 7, 3, 5, 9, 0, 3, 1, 2,\n",
       "       5, 6, 6, 8, 2, 0, 9, 4, 4, 1, 2, 0, 6, 6, 5, 7, 0, 4, 9, 2, 6, 8,\n",
       "       1, 9, 4, 0, 9, 0, 7, 6, 2, 0, 6, 9, 1, 0, 6, 6, 3, 4, 7, 9, 4, 2,\n",
       "       6, 5, 6, 0, 5, 5, 9, 8, 1, 8, 1, 0, 4, 9, 4, 5, 3, 4, 7, 7, 8, 9,\n",
       "       3, 1, 8, 8, 2, 4, 6, 4, 0, 9, 6, 6, 4, 2, 3, 6, 6, 4, 0, 1, 1, 7,\n",
       "       3, 7, 8, 0, 8, 6, 2, 3, 9, 2, 2, 1, 7, 4, 0, 4, 7, 5, 5, 7, 9, 1,\n",
       "       5, 4, 9, 4, 8, 1, 3, 4, 3, 1, 1, 4, 9, 5, 2, 4, 7, 6, 9, 6, 8, 0,\n",
       "       2, 1, 0, 8, 0, 2, 0, 9, 2, 9, 2, 3, 4, 2, 7, 9, 2, 4, 0, 8, 8, 1,\n",
       "       9, 2, 4, 4, 0, 3, 5, 5, 6, 5, 9, 7, 9, 4, 9, 3, 3, 8, 2, 0, 6, 6,\n",
       "       3, 0, 7, 2, 6, 0, 1, 1, 9, 9, 3, 7, 4, 1, 8, 9, 0, 3, 3, 0, 5, 2,\n",
       "       4, 2, 7, 7, 9, 0, 5, 8, 6, 2, 4, 2, 3, 4, 3, 8, 5, 8, 4, 5, 5, 2,\n",
       "       4, 9, 0, 3, 9, 2, 0, 5, 0, 1, 1, 7, 7, 1, 6, 3, 9, 5, 4, 3, 2, 1,\n",
       "       5, 4, 1, 9, 1, 8, 9, 3, 2, 7, 9, 8, 4, 4, 4, 4, 1, 6, 4, 6, 0, 2,\n",
       "       0, 9, 7, 7, 6, 1, 3, 3, 7, 3, 2, 4, 7, 3, 9, 1, 5, 5, 0, 2, 1, 3,\n",
       "       0, 9, 2, 4, 9, 0, 4, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0c92a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 33,  1,  0,  0,  0,  0,  0,  2,  0],\n",
       "       [ 0,  0, 44,  1,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0, 30,  0,  1,  0,  0,  0,  1],\n",
       "       [ 1,  0,  0,  0, 42,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 25,  0,  0,  0,  1],\n",
       "       [ 0,  1,  0,  0,  2,  0, 34,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 27,  0,  0],\n",
       "       [ 0,  1,  0,  2,  0,  0,  0,  0, 25,  1],\n",
       "       [ 0,  0,  0,  2,  1,  1,  0,  1,  0, 40]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "728ecc43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a230127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
